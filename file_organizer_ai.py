#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIæ™ºèƒ½åˆ†ç±»ä¸“ç”¨æ–‡ä»¶æ•´ç†æ ¸å¿ƒæ¨¡å—
"""
import os
import shutil
import logging
import json
from datetime import datetime
from typing import List, Dict, Tuple, Optional, Any
from pathlib import Path
import ollama
from transfer_log_manager import TransferLogManager
import PyPDF2
import docx
import time

class FileOrganizerError(Exception):
    pass

class OllamaClient:
    def __init__(self, model_name: Optional[str] = None, host: str = "http://localhost:11434"):
        self.model_name = model_name
        self.host = host
        self.client = ollama.Client(host=host)
        self._validate_connection()
    def _validate_connection(self) -> None:
        try:
            models_response = self.client.list()
            if hasattr(models_response, 'models'):
                models_list = models_response.models
            elif isinstance(models_response, dict) and 'models' in models_response:
                models_list = models_response['models']
            else:
                models_list = models_response if isinstance(models_response, list) else []
            self.available_models = []
            for model in models_list:
                if isinstance(model, dict):
                    if 'name' in model:
                        model_name = model['name']
                        # ç¡®ä¿æ¨¡å‹åç§°æ˜¯å­—ç¬¦ä¸²æ ¼å¼
                        if isinstance(model_name, str):
                            self.available_models.append(model_name)
                        else:
                            self.available_models.append(str(model_name))
                    elif 'model' in model:
                        model_name = model['model']
                        if isinstance(model_name, str):
                            self.available_models.append(model_name)
                        else:
                            self.available_models.append(str(model_name))
                elif isinstance(model, str):
                    self.available_models.append(model)
                else:
                    # å¦‚æœæ˜¯å…¶ä»–ç±»å‹ï¼Œå°è¯•æå–modelæˆ–nameå±æ€§
                    model_name = None
                    if hasattr(model, 'model'):
                        model_name = getattr(model, 'model')
                    elif hasattr(model, 'name'):
                        model_name = getattr(model, 'name')
                    
                    if model_name:
                        if isinstance(model_name, str):
                            self.available_models.append(model_name)
                        else:
                            self.available_models.append(str(model_name))
                    else:
                        # æœ€åå°è¯•ç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                        model_str = str(model)
                        # å¦‚æœå­—ç¬¦ä¸²åŒ…å«æ¨¡å‹ä¿¡æ¯ï¼Œå°è¯•æå–
                        if "model='" in model_str:
                            import re
                            match = re.search(r"model='([^']+)'", model_str)
                            if match:
                                self.available_models.append(match.group(1))
                            else:
                                self.available_models.append(model_str)
                        else:
                            self.available_models.append(model_str)
            if not self.available_models:
                raise FileOrganizerError("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œè¯·å…ˆæ‹‰å–æ¨¡å‹")
            if self.model_name is None or self.model_name not in self.available_models:
                if self.model_name is not None:
                    logging.warning(f"æ¨¡å‹ {self.model_name} ä¸å¯ç”¨ï¼Œä½¿ç”¨ {self.available_models[0]}")
                self.model_name = self.available_models[0]
                logging.info(f"è‡ªåŠ¨é€‰æ‹©æ¨¡å‹: {self.model_name}")
            logging.info(f"æˆåŠŸè¿æ¥åˆ° Ollamaï¼Œä½¿ç”¨æ¨¡å‹: {self.model_name}")
            logging.info(f"å¯ç”¨æ¨¡å‹åˆ—è¡¨: {self.available_models}")
        except Exception as e:
            raise FileOrganizerError(f"è¿æ¥ Ollama å¤±è´¥: {e}")
    def chat_with_retry(self, messages: List[Dict], max_retries: Optional[int] = None) -> str:
        if max_retries is None:
            max_retries = len(self.available_models)
        last_error = None
        models_to_try = [self.model_name] + [m for m in self.available_models if m != self.model_name]
        for attempt, model_name in enumerate(models_to_try[:max_retries]):
            try:
                client = ollama.Client(host=self.host)
                if not isinstance(model_name, str) or not model_name:
                    raise FileOrganizerError("æ¨¡å‹åæ— æ•ˆï¼Œæ— æ³•è°ƒç”¨ chat")
                response = client.chat(
                    model=model_name,
                    messages=messages
                )
                if model_name != self.model_name:
                    logging.info(f"æ¨¡å‹åˆ‡æ¢: {self.model_name} -> {model_name}")
                    self.model_name = model_name
                return response['message']['content'].strip()
            except Exception as e:
                last_error = e
                logging.warning(f"æ¨¡å‹ {model_name} å“åº”å¤±è´¥: {e}")
                if attempt < max_retries - 1:
                    continue
        raise FileOrganizerError(f"æ‰€æœ‰å¯ç”¨æ¨¡å‹éƒ½å“åº”å¤±è´¥ï¼Œæœ€åé”™è¯¯: {last_error}")

class FileOrganizer:
    def __init__(self, model_name: Optional[str] = None, enable_transfer_log: bool = True):
        self.model_name = model_name
        self.ollama_client = None
        self.enable_transfer_log = enable_transfer_log
        self.transfer_log_manager = None
        
        # AIå‚æ•°è®¾ç½®
        self.summary_length = 100  # æ‘˜è¦é•¿åº¦ï¼Œé»˜è®¤100å­—ç¬¦
        self.content_truncate = 500  # å†…å®¹æˆªå–ï¼Œé»˜è®¤500å­—ç¬¦
        
        if self.enable_transfer_log:
            try:
                self.transfer_log_manager = TransferLogManager()
                logging.info("è½¬ç§»æ—¥å¿—ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logging.warning(f"è½¬ç§»æ—¥å¿—ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                self.enable_transfer_log = False
        self.setup_logging()
    def setup_logging(self) -> None:
        log_filename = f"file_organizer_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        log_path = os.path.join(os.path.dirname(__file__), "logs", log_filename)
        os.makedirs(os.path.dirname(log_path), exist_ok=True)
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_path, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        logging.info("æ–‡ä»¶æ•´ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    def initialize_ollama(self) -> None:
        try:
            self.ollama_client = OllamaClient(self.model_name)
            logging.info("Ollama å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            raise FileOrganizerError(f"åˆå§‹åŒ– Ollama å®¢æˆ·ç«¯å¤±è´¥: {e}")
    def scan_target_folders(self, target_directory: str) -> List[str]:
        try:
            target_path = Path(target_directory)
            if not target_path.exists():
                raise FileOrganizerError(f"ç›®æ ‡ç›®å½•ä¸å­˜åœ¨: {target_directory}")
            folders = []
            for item in target_path.rglob('*'):
                if item.is_dir():
                    relative_path = item.relative_to(target_path)
                    folders.append(str(relative_path))
            logging.info(f"æ‰«æåˆ° {len(folders)} ä¸ªç›®æ ‡æ–‡ä»¶å¤¹ï¼ˆåŒ…å«å­ç›®å½•ï¼‰")
            return folders
        except Exception as e:
            raise FileOrganizerError(f"æ‰«æç›®æ ‡æ–‡ä»¶å¤¹å¤±è´¥: {e}")
    def get_directory_tree_structure(self, target_directory: str) -> str:
        try:
            target_path = Path(target_directory)
            if not target_path.exists():
                raise FileOrganizerError(f"ç›®æ ‡ç›®å½•ä¸å­˜åœ¨: {target_directory}")
            def build_tree(path: Path, prefix: str = "", is_last: bool = True) -> List[str]:
                lines = []
                if path != target_path:
                    connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
                    lines.append(f"{prefix}{connector}{path.name}")
                    prefix += "    " if is_last else "â”‚   "
                subdirs = sorted([item for item in path.iterdir() if item.is_dir()], key=lambda x: x.name)
                for i, subdir in enumerate(subdirs):
                    is_last_subdir = (i == len(subdirs) - 1)
                    lines.extend(build_tree(subdir, prefix, is_last_subdir))
                return lines
            tree_lines = build_tree(target_path)
            tree_structure = "\n".join(tree_lines)
            logging.info(f"ç”Ÿæˆç›®å½•æ ‘ç»“æ„ï¼Œå…± {len(tree_lines)} è¡Œ")
            return tree_structure
        except Exception as e:
            raise FileOrganizerError(f"ç”Ÿæˆç›®å½•æ ‘ç»“æ„å¤±è´¥: {e}")
    def analyze_and_classify_file(self, file_path: str, target_directory: str) -> Dict[str, Any]:
        """
        æ–°çš„æ–‡ä»¶åˆ†æå’Œåˆ†ç±»æ–¹æ³•ï¼šå…ˆè§£æå†…å®¹ï¼Œç”Ÿæˆæ‘˜è¦ï¼Œå†æ¨èç›®å½•
        è¿”å›åŒ…å«æå–å†…å®¹ã€æ‘˜è¦å’Œæ¨èç›®å½•çš„å®Œæ•´ç»“æœ
        """
        start_time = time.time()
        timing_info = {}
        
        try:
            if not self.ollama_client:
                init_start = time.time()
                self.initialize_ollama()
                timing_info['ollama_init_time'] = round(time.time() - init_start, 3)
            
            file_name = Path(file_path).name
            logging.info(f"å¼€å§‹åˆ†ææ–‡ä»¶: {file_name}")
            
            # ç¬¬ä¸€æ­¥ï¼šè§£ææ–‡ä»¶å†…å®¹
            extract_start = time.time()
            extracted_content = self._extract_file_content(file_path)
            extract_time = round(time.time() - extract_start, 3)
            timing_info['content_extraction_time'] = extract_time
            logging.info(f"æ–‡ä»¶å†…å®¹æå–å®Œæˆï¼Œé•¿åº¦: {len(extracted_content)} å­—ç¬¦ï¼Œè€—æ—¶: {extract_time}ç§’")
            
            # æ ¹æ®è®¾ç½®æˆªå–å†…å®¹ç”¨äºåç»­AIå¤„ç†ï¼Œæé«˜å¤„ç†æ•ˆç‡
            truncate_length = self.content_truncate if self.content_truncate < 2000 else len(extracted_content)
            content_for_ai = extracted_content[:truncate_length] if extracted_content else ""
            if len(extracted_content) > truncate_length:
                logging.info(f"å†…å®¹å·²æˆªå–è‡³å‰{truncate_length}å­—ç¬¦ç”¨äºAIå¤„ç†ï¼ˆåŸé•¿åº¦: {len(extracted_content)} å­—ç¬¦ï¼‰")
            
            # ç¬¬äºŒæ­¥ï¼šç”Ÿæˆ100å­—æ‘˜è¦ï¼ˆä½¿ç”¨æˆªå–åçš„å†…å®¹ï¼‰
            summary_start = time.time()
            summary = self._generate_content_summary(content_for_ai, file_name)
            summary_time = round(time.time() - summary_start, 3)
            timing_info['summary_generation_time'] = summary_time
            logging.info(f"å†…å®¹æ‘˜è¦ç”Ÿæˆå®Œæˆ: {summary[:50]}...ï¼Œè€—æ—¶: {summary_time}ç§’")
            
            # ç¬¬ä¸‰æ­¥ï¼šæ¨èæœ€åŒ¹é…çš„å­˜æ”¾ç›®å½•ï¼ˆä½¿ç”¨æˆªå–åçš„å†…å®¹ï¼‰
            recommend_start = time.time()
            recommended_folder, match_reason = self._recommend_target_folder(
                file_name, content_for_ai, summary, target_directory
            )
            recommend_time = round(time.time() - recommend_start, 3)
            timing_info['folder_recommendation_time'] = recommend_time
            
            total_time = round(time.time() - start_time, 3)
            timing_info['total_processing_time'] = total_time
            
            result = {
                'file_path': file_path,
                'file_name': file_name,
                'extracted_content': extracted_content,
                'content_summary': summary,
                'recommended_folder': recommended_folder,
                'match_reason': match_reason,
                'success': recommended_folder is not None,
                'timing_info': timing_info
            }
            
            if recommended_folder:
                logging.info(f"æ–‡ä»¶åˆ†æå®Œæˆ: {file_name} -> {recommended_folder}ï¼Œæ€»è€—æ—¶: {total_time}ç§’")
                logging.info(f"æ‘˜è¦: {summary}")
                logging.info(f"æ¨èç†ç”±: {match_reason}")
                logging.info(f"è¯¦ç»†è€—æ—¶ - å†…å®¹æå–: {extract_time}ç§’, æ‘˜è¦ç”Ÿæˆ: {summary_time}ç§’, ç›®å½•æ¨è: {recommend_time}ç§’")
            else:
                logging.warning(f"æ–‡ä»¶åˆ†æå¤±è´¥: {file_name}ï¼Œæ€»è€—æ—¶: {total_time}ç§’")
            
            return result
            
        except Exception as e:
            total_time = round(time.time() - start_time, 3)
            timing_info['total_processing_time'] = total_time
            logging.error(f"æ–‡ä»¶åˆ†æå¤±è´¥: {e}ï¼Œæ€»è€—æ—¶: {total_time}ç§’")
            return {
                'file_path': file_path,
                'file_name': Path(file_path).name,
                'extracted_content': '',
                'content_summary': '',
                'recommended_folder': None,
                'match_reason': f"åˆ†æå¤±è´¥: {str(e)}",
                'success': False,
                'error': str(e),
                'timing_info': timing_info
            }
    
    def classify_file(self, file_path: str, target_directory: str) -> tuple:
        """
        ä¿æŒåŸæœ‰çš„åˆ†ç±»æ–¹æ³•å…¼å®¹æ€§
        """
        result = self.analyze_and_classify_file(file_path, target_directory)
        return result['recommended_folder'], result['match_reason'], result['success']
    def _build_classification_prompt(self, file_path: str, target_directory: str) -> str:
        file_name = Path(file_path).name
        file_extension = Path(file_path).suffix.lower()
        file_content = ""
        content_readable = False
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                file_content = f.read()[:2000]
                printable_ratio = sum(1 for c in file_content if c.isprintable() or c.isspace()) / len(file_content) if file_content else 0
                if printable_ratio > 0.7:
                    content_readable = True
                else:
                    file_content = "æ–‡ä»¶å†…å®¹ä¸ºäºŒè¿›åˆ¶æ ¼å¼ï¼Œæ— æ³•è¯»å–"
        except Exception:
            for encoding in ['gbk', 'gb2312', 'latin-1']:
                try:
                    with open(file_path, 'r', encoding=encoding, errors='ignore') as f:
                        file_content = f.read()[:2000]
                        printable_ratio = sum(1 for c in file_content if c.isprintable() or c.isspace()) / len(file_content) if file_content else 0
                        if printable_ratio > 0.7:
                            content_readable = True
                            break
                        else:
                            file_content = "æ–‡ä»¶å†…å®¹ä¸ºäºŒè¿›åˆ¶æ ¼å¼ï¼Œæ— æ³•è¯»å–"
                except Exception:
                    continue
            if not content_readable:
                file_content = "æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹"
        directory_structure = self.get_directory_tree_structure(target_directory)
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡ä»¶åˆ†ç±»åŠ©æ‰‹ã€‚è¯·é˜…è¯»åŸæ–‡ä»¶çš„å‰500ä¸ªå­—ï¼Œæˆ–è€…è¯†åˆ«ç¬¬ä¸€é¡µå†…å®¹ï¼Œæ ¹æ®æ–‡ä»¶å†…å®¹åˆ¤æ–­æ–‡ä»¶åº”è¯¥å½’ç±»åˆ°ä¸‹åˆ—å“ªä¸ªæ–‡ä»¶å¤¹ä¸­ï¼Œæ³¨æ„ï¼Œæ¯ä¸ªæ–‡ä»¶æ ¹æ®æ–‡ä»¶å†…å®¹åªåŒ¹é…ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼ŒåŒ¹é…åŸåˆ™æ˜¯ï¼š

- ä¼˜å…ˆåŒ¹é…ï¼šæ–‡ä»¶å†…å®¹ä¸»é¢˜å’Œæ–‡ä»¶å¤¹ååŠæ–‡ä»¶è·¯å¾„åæœ€ç›¸ç¬¦
- é™çº§åŒ¹é…ï¼šå¦‚æœè¯»å–ä¸åˆ°æ–‡ä»¶å†…å®¹ï¼Œåˆ™ç”¨åŸæ–‡ä»¶åå’Œç›®æ ‡æ–‡ä»¶å¤¹ååŠæ–‡ä»¶å¤¹è·¯å¾„åæ¥åŒ¹é…

æ–‡ä»¶ä¿¡æ¯ï¼š
- åŸæ–‡ä»¶åï¼š{file_name}
- æ–‡ä»¶æ‰©å±•åï¼š{file_extension}
- æ–‡ä»¶å†…å®¹ï¼š{file_content if content_readable else "æ— æ³•è¯»å–å†…å®¹"}

ç›®æ ‡ç›®å½•æ–‡ä»¶å¤¹æ¸…å•å¦‚ä¸‹ï¼š
{directory_structure}

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
åŸæ–‡ä»¶å|ç›®æ ‡æ–‡ä»¶å¤¹|åŒ¹é…ç†ç”±

å…¶ä¸­åŒ¹é…ç†ç”±æ ¼å¼ä¸ºï¼š
å†…å®¹åŒ¹é…ï¼š{{ç”¨ä¸å¤šäº20ä¸ªå­—æè¿°åŒ¹é…ç†ç”±}}
æˆ–è€…
æ— æ³•è¯»å–å†…å®¹ï¼Œé‡‡ç”¨æ–‡ä»¶å¤¹ååŒ¹é…ï¼š{{ç”¨ä¸å¤šäº20ä¸ªå­—æè¿°åŒ¹é…ç†ç”±}}

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¾“å‡ºï¼Œåªè¾“å‡ºä¸€è¡Œç»“æœã€‚
"""
        return prompt
    
    def _extract_file_content(self, file_path: str, max_length: int = 3000) -> str:
        """
        æå–æ–‡ä»¶å†…å®¹ï¼ˆä»file_reader.pyå¤åˆ¶çš„å®Œæ•´å®ç°ï¼‰
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            max_length: æœ€å¤§æå–é•¿åº¦
            
        Returns:
            æå–çš„æ–‡ä»¶å†…å®¹
        """
        try:
            file_path = Path(file_path)
            if not file_path.exists():
                raise Exception(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
            file_extension = file_path.suffix.lower()
            logging.info(f"æ­£åœ¨æå–æ–‡ä»¶å†…å®¹: {file_path.name} (ç±»å‹: {file_extension})")
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©ä¸åŒçš„æå–æ–¹æ³•
            if file_extension == '.pdf':
                return self._extract_pdf_content(file_path, max_length)
            elif file_extension in ['.docx', '.doc']:
                return self._extract_docx_content(file_path, max_length)
            elif file_extension in ['.txt', '.md', '.py', '.js', '.html', '.css', '.json', '.xml', '.csv']:
                return self._extract_text_content(file_path, max_length)
            elif file_extension in ['.jpg', '.jpeg', '.png', '.bmp', '.gif']:
                return self._extract_image_info(file_path)
            else:
                # å°è¯•ä½œä¸ºæ–‡æœ¬æ–‡ä»¶è¯»å–
                return self._extract_text_content(file_path, max_length)
                
        except Exception as e:
            logging.error(f"æå–æ–‡ä»¶å†…å®¹å¤±è´¥: {e}")
            return f"æ— æ³•æå–æ–‡ä»¶å†…å®¹: {str(e)}"
    
    def _extract_pdf_content(self, file_path: Path, max_length: int) -> str:
        """
        æå–PDFæ–‡ä»¶å†…å®¹ï¼ˆä»file_reader.pyå¤åˆ¶çš„å®Œæ•´å®ç°ï¼‰
        """
        try:
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                content = ""
                
                # è¯»å–å‰å‡ é¡µå†…å®¹
                for page_num in range(min(3, len(pdf_reader.pages))):
                    page = pdf_reader.pages[page_num]
                    content += page.extract_text() + "\n"
                    
                    if len(content) >= max_length:
                        break
                
                return content[:max_length] if content else "PDFæ–‡ä»¶å†…å®¹ä¸ºç©ºæˆ–æ— æ³•æå–"
                
        except Exception as e:
            return f"PDFæ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}"
    
    def _extract_docx_content(self, file_path: Path, max_length: int) -> str:
        """
        æå–Wordæ–‡æ¡£å†…å®¹ï¼ˆä»file_reader.pyå¤åˆ¶çš„å®Œæ•´å®ç°ï¼‰
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯è¯»
            if not file_path.exists():
                return "æ–‡ä»¶ä¸å­˜åœ¨"
            
            if not file_path.is_file():
                return "è·¯å¾„ä¸æ˜¯æ–‡ä»¶"
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = file_path.stat().st_size
            if file_size == 0:
                return "æ–‡ä»¶ä¸ºç©º"
            
            # å°è¯•è¯»å–Wordæ–‡æ¡£
            try:
                doc = docx.Document(file_path)
                content = ""
                
                # æå–æ®µè½å†…å®¹
                for paragraph in doc.paragraphs:
                    if paragraph.text.strip():  # è·³è¿‡ç©ºæ®µè½
                        content += paragraph.text.strip() + "\n"
                        if len(content) >= max_length:
                            break
                
                # å¦‚æœæ®µè½å†…å®¹ä¸ºç©ºï¼Œå°è¯•æå–è¡¨æ ¼å†…å®¹
                if not content.strip():
                    for table in doc.tables:
                        for row in table.rows:
                            for cell in row.cells:
                                if cell.text.strip():
                                    content += cell.text.strip() + " "
                        content += "\n"
                        if len(content) >= max_length:
                            break
                
                return content[:max_length].strip() if content.strip() else "Wordæ–‡æ¡£å†…å®¹ä¸ºç©ºæˆ–æ— æ³•æå–"
                
            except Exception as docx_error:
                # å¦‚æœæ˜¯.docæ–‡ä»¶æˆ–æŸåçš„.docxæ–‡ä»¶ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
                if file_path.suffix.lower() == '.doc':
                    return "ä¸æ”¯æŒ.docæ ¼å¼ï¼Œè¯·è½¬æ¢ä¸º.docxæ ¼å¼"
                else:
                    return f"Wordæ–‡æ¡£æ ¼å¼é”™è¯¯æˆ–æ–‡ä»¶æŸå: {str(docx_error)}"
            
        except Exception as e:
            return f"Wordæ–‡æ¡£è¯»å–å¤±è´¥: {str(e)}"
    
    def _extract_text_content(self, file_path: Path, max_length: int) -> str:
        """
        æå–æ–‡æœ¬æ–‡ä»¶å†…å®¹ï¼ˆä»file_reader.pyå¤åˆ¶çš„å®Œæ•´å®ç°ï¼‰
        """
        try:
            # å°è¯•å¤šç§ç¼–ç æ ¼å¼
            encodings = ['utf-8', 'gbk', 'gb2312', 'latin-1']
            
            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding, errors='ignore') as f:
                        content = f.read(max_length)
                        
                        # æ£€æŸ¥å†…å®¹æ˜¯å¦å¯è¯»
                        printable_ratio = sum(1 for c in content if c.isprintable() or c.isspace()) / len(content) if content else 0
                        if printable_ratio > 0.7:
                            return content
                        
                except Exception:
                    continue
            
            return "æ–‡ä»¶å†…å®¹ä¸ºäºŒè¿›åˆ¶æ ¼å¼ï¼Œæ— æ³•è¯»å–"
            
        except Exception as e:
            return f"æ–‡æœ¬æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}"
    
    def _extract_image_info(self, file_path: Path) -> str:
        """
        æå–å›¾ç‰‡æ–‡ä»¶ä¿¡æ¯ï¼ˆä»file_reader.pyå¤åˆ¶çš„å®Œæ•´å®ç°ï¼‰
        """
        try:
            from PIL import Image
            with Image.open(file_path) as img:
                info = f"å›¾ç‰‡æ–‡ä»¶ä¿¡æ¯:\n"
                info += f"æ ¼å¼: {img.format}\n"
                info += f"å°ºå¯¸: {img.size[0]} x {img.size[1]}\n"
                info += f"æ¨¡å¼: {img.mode}\n"
                
                # å¦‚æœæœ‰EXIFä¿¡æ¯ï¼Œæå–ä¸€äº›åŸºæœ¬ä¿¡æ¯
                if hasattr(img, '_getexif') and img._getexif():
                    info += "åŒ…å«EXIFä¿¡æ¯\n"
                
                return info
                
        except Exception as e:
            return f"å›¾ç‰‡æ–‡ä»¶ä¿¡æ¯æå–å¤±è´¥: {str(e)}"
    
    def _generate_content_summary(self, content: str, file_name: str) -> str:
        """
        ç”Ÿæˆæ–‡ä»¶å†…å®¹æ‘˜è¦
        """
        try:
            if not content or content.startswith("æ— æ³•") or content.startswith("æ–‡ä»¶å†…å®¹ä¸ºäºŒè¿›åˆ¶"):
                return f"æ— æ³•ç”Ÿæˆæ‘˜è¦ï¼š{content[:50]}..."
            
            if not self.ollama_client:
                self.initialize_ollama()
            
            prompt = f"""
è¯·ä¸ºä»¥ä¸‹æ–‡ä»¶å†…å®¹ç”Ÿæˆä¸€ä¸ª{self.summary_length}å­—ä»¥å†…çš„ä¸­æ–‡æ‘˜è¦ï¼Œè¦æ±‚ï¼š
1. æ¦‚æ‹¬æ–‡ä»¶çš„ä¸»è¦å†…å®¹å’Œä¸»é¢˜
2. çªå‡ºå…³é”®ä¿¡æ¯å’Œè¦ç‚¹
3. è¯­è¨€ç®€æ´æ˜äº†
4. å­—æ•°æ§åˆ¶åœ¨{self.summary_length}å­—ä»¥å†…

æ–‡ä»¶åï¼š{file_name}
æ–‡ä»¶å†…å®¹ï¼š
{content}

è¯·ç›´æ¥è¾“å‡ºæ‘˜è¦å†…å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜æ–‡å­—ï¼š
"""
            
            summary = self.ollama_client.chat_with_retry([
                {
                    'role': 'user',
                    'content': prompt
                }
            ])
            
            # ç¡®ä¿æ‘˜è¦é•¿åº¦ä¸è¶…è¿‡100å­—
            if len(summary) > 100:
                summary = summary[:97] + "..."
            
            return summary.strip()
            
        except Exception as e:
            logging.error(f"ç”Ÿæˆæ‘˜è¦å¤±è´¥: {e}")
            return f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def _recommend_target_folder(self, file_name: str, content: str, summary: str, target_directory: str) -> tuple:
        """
        åŸºäºæ–‡ä»¶å†…å®¹å’Œæ‘˜è¦æ¨èæœ€åŒ¹é…çš„ç›®æ ‡æ–‡ä»¶å¤¹
        """
        try:
            if not self.ollama_client:
                self.initialize_ollama()
            
            target_folders = self.scan_target_folders(target_directory)
            directory_structure = self.get_directory_tree_structure(target_directory)
            
            # åˆ¤æ–­æ˜¯å¦æœ‰æœ‰æ•ˆçš„å†…å®¹å’Œæ‘˜è¦
            has_valid_content = content and not content.startswith("æ— æ³•") and not content.startswith("æ–‡ä»¶å†…å®¹ä¸ºäºŒè¿›åˆ¶")
            has_valid_summary = summary and not summary.startswith("æ— æ³•") and not summary.startswith("æ‘˜è¦ç”Ÿæˆå¤±è´¥")
            
            if has_valid_content and has_valid_summary:
                # æœ‰å†…å®¹å’Œæ‘˜è¦æ—¶ï¼Œä¼˜å…ˆä½¿ç”¨æ‘˜è¦è¿›è¡Œåˆ†ç±»
                prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡ä»¶åˆ†ç±»åŠ©æ‰‹ã€‚è¯·æ ¹æ®æ–‡ä»¶çš„å†…å®¹æ‘˜è¦ï¼Œæ¨èæœ€é€‚åˆçš„å­˜æ”¾æ–‡ä»¶å¤¹ã€‚

æ–‡ä»¶ä¿¡æ¯ï¼š
- æ–‡ä»¶åï¼š{file_name}
- å†…å®¹æ‘˜è¦ï¼š{summary}

å¯é€‰çš„ç›®æ ‡æ–‡ä»¶å¤¹ï¼š
{directory_structure}

åˆ†ç±»åŸåˆ™ï¼š
1. ä¼˜å…ˆæ ¹æ®æ–‡ä»¶å†…å®¹ä¸»é¢˜åŒ¹é…æ–‡ä»¶å¤¹
2. è€ƒè™‘æ–‡ä»¶çš„ç”¨é€”å’Œæ€§è´¨
3. é€‰æ‹©æœ€å…·ä½“ã€æœ€ç›¸å…³çš„æ–‡ä»¶å¤¹

è¾“å‡ºæ ¼å¼ï¼š
æ–‡ä»¶å|æ¨èæ–‡ä»¶å¤¹|æ¨èç†ç”±

æ¨èç†ç”±æ ¼å¼ï¼š
å†…å®¹åŒ¹é…ï¼š{{ç®€è¿°åŒ¹é…åŸå› ï¼Œä¸è¶…è¿‡30å­—}}

è¯·ä¸¥æ ¼æŒ‰ç…§æ ¼å¼è¾“å‡ºä¸€è¡Œç»“æœï¼š
"""
            else:
                # æ— æ³•è·å–æœ‰æ•ˆå†…å®¹æ—¶ï¼Œä½¿ç”¨æ–‡ä»¶åè¿›è¡Œåˆ†ç±»
                file_extension = Path(file_name).suffix.lower()
                prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡ä»¶åˆ†ç±»åŠ©æ‰‹ã€‚ç”±äºæ— æ³•è¯»å–æ–‡ä»¶å†…å®¹ï¼Œè¯·æ ¹æ®æ–‡ä»¶åå’Œæ‰©å±•åæ¨èæœ€é€‚åˆçš„å­˜æ”¾æ–‡ä»¶å¤¹ã€‚

æ–‡ä»¶ä¿¡æ¯ï¼š
- æ–‡ä»¶åï¼š{file_name}
- æ–‡ä»¶æ‰©å±•åï¼š{file_extension}
- å†…å®¹çŠ¶æ€ï¼š{content[:100] if content else "æ— å†…å®¹"}

å¯é€‰çš„ç›®æ ‡æ–‡ä»¶å¤¹ï¼š
{directory_structure}

åˆ†ç±»åŸåˆ™ï¼š
1. æ ¹æ®æ–‡ä»¶æ‰©å±•ååŒ¹é…ç›¸åº”ç±»å‹çš„æ–‡ä»¶å¤¹
2. æ ¹æ®æ–‡ä»¶åå…³é”®è¯åŒ¹é…ä¸»é¢˜æ–‡ä»¶å¤¹
3. é€‰æ‹©æœ€å…·ä½“ã€æœ€ç›¸å…³çš„æ–‡ä»¶å¤¹

è¾“å‡ºæ ¼å¼ï¼š
æ–‡ä»¶å|æ¨èæ–‡ä»¶å¤¹|æ¨èç†ç”±

æ¨èç†ç”±æ ¼å¼ï¼š
æ–‡ä»¶ååŒ¹é…ï¼š{{ç®€è¿°åŒ¹é…åŸå› ï¼Œä¸è¶…è¿‡30å­—}}

è¯·ä¸¥æ ¼æŒ‰ç…§æ ¼å¼è¾“å‡ºä¸€è¡Œç»“æœï¼š
"""
            
            result = self.ollama_client.chat_with_retry([
                {
                    'role': 'user',
                    'content': prompt
                }
            ])
            
            return self._parse_classification_result(result, target_folders)
            
        except Exception as e:
            logging.error(f"æ¨èç›®æ ‡æ–‡ä»¶å¤¹å¤±è´¥: {e}")
            return None, f"æ¨èå¤±è´¥: {str(e)}"
    def _parse_classification_result(self, result: str, target_folders: List[str]) -> tuple:
        try:
            result = result.strip()
            
            # å¤„ç†å¤šè¡Œæ ¼å¼çš„ç»“æœï¼ŒæŸ¥æ‰¾åŒ…å«æ–‡ä»¶åå’Œæ¨èä¿¡æ¯çš„è¡Œ
            lines = result.split('\n')
            for line in lines:
                line = line.strip()
                if not line or line.startswith('---') or line.startswith('æ–‡ä»¶å|'):
                    continue
                
                parts = line.split('|')
                if len(parts) >= 3:
                    original_filename = parts[0].strip()
                    target_folder = parts[1].strip()
                    match_reason = parts[2].strip()
                    
                    # éªŒè¯ç›®æ ‡æ–‡ä»¶å¤¹æ˜¯å¦æœ‰æ•ˆ
                    if target_folder in target_folders:
                        return target_folder, match_reason
                    else:
                        # å°è¯•æ¨¡ç³ŠåŒ¹é…
                        for valid_folder in target_folders:
                            if target_folder in valid_folder or valid_folder in target_folder:
                                return valid_folder, f"{match_reason}ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼š{target_folder}ï¼‰"
                        
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶å¤¹ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€è¡Œ
                        continue
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„åˆ†ç±»ç»“æœï¼Œå°è¯•åŸæ¥çš„å•è¡Œè§£æ
            parts = result.split('|')
            if len(parts) >= 3:
                original_filename = parts[0].strip()
                target_folder = parts[1].strip()
                match_reason = parts[2].strip()
                
                if target_folder in target_folders:
                    return target_folder, match_reason
                else:
                    for valid_folder in target_folders:
                        if target_folder in valid_folder or valid_folder in target_folder:
                            return valid_folder, f"{match_reason}ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼š{target_folder}ï¼‰"
            
            logging.warning(f"æ— æ³•è§£æåˆ†ç±»ç»“æœæˆ–æ‰¾ä¸åˆ°æœ‰æ•ˆçš„ç›®æ ‡æ–‡ä»¶å¤¹: {result}")
            return None, None
            
        except Exception as e:
            logging.warning(f"è§£æåˆ†ç±»ç»“æœå¤±è´¥: {e}, åŸå§‹ç»“æœ: {result}")
            return None, None
    def scan_source_files(self, source_directory: str) -> List[str]:
        try:
            source_path = Path(source_directory)
            if not source_path.exists():
                raise FileOrganizerError(f"æºç›®å½•ä¸å­˜åœ¨: {source_directory}")
            files = []
            for item in source_path.rglob('*'):
                if item.is_file():
                    files.append(str(item))
            logging.info(f"æ‰«æåˆ° {len(files)} ä¸ªå¾…æ•´ç†æ–‡ä»¶")
            return files
        except Exception as e:
            raise FileOrganizerError(f"æ‰«ææºæ–‡ä»¶å¤±è´¥: {e}")
    def scan_files(self, source_directory: str) -> List[Dict[str, object]]:
        try:
            source_path = Path(source_directory)
            if not source_path.exists():
                raise FileOrganizerError(f"æºç›®å½•ä¸å­˜åœ¨: {source_directory}")
            files = []
            for item in source_path.rglob('*'):
                if item.is_file():
                    files.append({
                        'name': item.name,
                        'path': str(item),
                        'size': item.stat().st_size,
                        'extension': item.suffix.lower()
                    })
            logging.info(f"æ‰«æåˆ° {len(files)} ä¸ªå¾…æ•´ç†æ–‡ä»¶")
            return files
        except Exception as e:
            raise FileOrganizerError(f"æ‰«ææºæ–‡ä»¶å¤±è´¥: {e}")
    def get_target_folders(self, target_directory: str) -> List[str]:
        return self.scan_target_folders(target_directory)
    def preview_classification(self, source_directory: str, target_directory: str) -> List[Dict[str, object]]:
        try:
            source_files = self.scan_source_files(source_directory)
            if not source_files:
                raise FileOrganizerError("æºç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶")
            preview_results = []
            logging.info(f"å¼€å§‹é¢„è§ˆåˆ†ç±»ï¼Œå…± {len(source_files)} ä¸ªæ–‡ä»¶ï¼Œä»…åˆ†æå‰10ä¸ª")
            preview_count = min(10, len(source_files))
            for i, file_path in enumerate(source_files[:preview_count], 1):
                file_name = Path(file_path).name
                try:
                    logging.info(f"æ­£åœ¨å¤„ç†æ–‡ä»¶ {i}/{preview_count}: {file_name}")
                    # ä½¿ç”¨æ–°çš„åˆ†ææ–¹æ³•
                    analysis_result = self.analyze_and_classify_file(file_path, target_directory)
                    
                    if analysis_result['success']:
                        timing_info = analysis_result.get('timing_info', {})
                        preview_results.append({
                            'file_path': file_path,
                            'file_name': file_name,
                            'target_folder': analysis_result['recommended_folder'],
                            'match_reason': analysis_result['match_reason'],
                            'classification_method': 'AI_Enhanced',
                            'success': True,
                            'extracted_content': analysis_result['extracted_content'][:200] + "..." if len(analysis_result['extracted_content']) > 200 else analysis_result['extracted_content'],
                            'content_summary': analysis_result['content_summary'],
                            'timing_info': timing_info
                        })
                        total_time = timing_info.get('total_processing_time', 0)
                        extract_time = timing_info.get('content_extraction_time', 0)
                        summary_time = timing_info.get('summary_generation_time', 0)
                        recommend_time = timing_info.get('folder_recommendation_time', 0)
                        
                        logging.info(f"æ–‡ä»¶ {file_name} åˆ†ææˆåŠŸ: {analysis_result['recommended_folder']} ({analysis_result['match_reason']})ï¼Œæ€»è€—æ—¶: {total_time}ç§’")
                        logging.info(f"å†…å®¹æ‘˜è¦: {analysis_result['content_summary']}")
                        logging.info(f"è¯¦ç»†è€—æ—¶ - å†…å®¹æå–: {extract_time}ç§’, æ‘˜è¦ç”Ÿæˆ: {summary_time}ç§’, ç›®å½•æ¨è: {recommend_time}ç§’")
                    else:
                        timing_info = analysis_result.get('timing_info', {})
                        preview_results.append({
                            'file_path': file_path,
                            'file_name': file_name,
                            'target_folder': None,
                            'match_reason': analysis_result['match_reason'],
                            'classification_method': 'Failed',
                            'success': False,
                            'error': analysis_result.get('error', analysis_result['match_reason']),
                            'extracted_content': analysis_result.get('extracted_content', ''),
                            'content_summary': analysis_result.get('content_summary', ''),
                            'timing_info': timing_info
                        })
                        total_time = timing_info.get('total_processing_time', 0)
                        logging.warning(f"æ–‡ä»¶ {file_name} åˆ†æå¤±è´¥: {analysis_result['match_reason']}ï¼Œæ€»è€—æ—¶: {total_time}ç§’")
                except Exception as e:
                    error_msg = f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"
                    logging.error(f"æ–‡ä»¶ {file_name} å¤„ç†å¼‚å¸¸: {e}")
                    preview_results.append({
                        'file_path': file_path,
                        'file_name': file_name,
                        'target_folder': None,
                        'match_reason': error_msg,
                        'classification_method': 'Error',
                        'success': False,
                        'error': error_msg
                    })
            success_count = sum(1 for result in preview_results if result['success'])
            logging.info(f"é¢„è§ˆåˆ†ç±»å®Œæˆï¼ŒæˆåŠŸåˆ†ç±» {success_count}/{len(preview_results)} ä¸ªæ–‡ä»¶")
            return preview_results
        except Exception as e:
            raise FileOrganizerError(f"é¢„è§ˆåˆ†ç±»å¤±è´¥: {e}")
    def organize_file(self, file_path: str, target_directory: str, target_folders: List[str]) -> Tuple[bool, str]:
        try:
            if not self.ollama_client:
                self.initialize_ollama()
            file_path_obj = Path(file_path)
            filename = file_path_obj.name
            # recommended_folders = self.ollama_client.classify_file(filename, target_folders)
            target_folder, match_reason, success = self.classify_file(str(file_path_obj), target_directory)
            if not success or not target_folder:
                return False, "æ— æ³•ç¡®å®šç›®æ ‡æ–‡ä»¶å¤¹"
            # target_folder = recommended_folders[0]  # å·²ç”±ä¸Šé¢è·å¾—
            target_folder_path = Path(target_directory) / target_folder
            target_folder_path.mkdir(parents=True, exist_ok=True)
            target_file_path = target_folder_path / filename
            if target_file_path.exists():
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                name_parts = filename.rsplit('.', 1)
                if len(name_parts) == 2:
                    new_filename = f"{name_parts[0]}_{timestamp}.{name_parts[1]}"
                else:
                    new_filename = f"{filename}_{timestamp}"
                target_file_path = target_folder_path / new_filename
            shutil.copy2(file_path, target_file_path)
            logging.info(f"æ–‡ä»¶å·²å¤åˆ¶: {file_path} -> {target_file_path}")
            return True, str(target_file_path)
        except Exception as e:
            error_msg = f"æ•´ç†æ–‡ä»¶å¤±è´¥: {e}"
            logging.error(error_msg)
            return False, error_msg
    def organize_files(self, files=None, target_folders=None, target_base_dir=None, copy_mode=True, source_directory=None, target_directory=None, dry_run=False, progress_callback=None) -> Dict[str, object]:
        try:
            if source_directory and target_directory:
                target_folders = self.scan_target_folders(target_directory)
                files = self.scan_files(source_directory)
                target_base_dir = target_directory
                copy_mode = True
            if not files or not target_folders or not target_base_dir:
                raise FileOrganizerError("ç¼ºå°‘å¿…è¦å‚æ•°")
            log_session_name = None
            if self.enable_transfer_log and self.transfer_log_manager and not dry_run:
                try:
                    session_name = f"organize_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    log_session_name = self.transfer_log_manager.start_transfer_session(session_name)
                    logging.info(f"å¼€å§‹è½¬ç§»æ—¥å¿—ä¼šè¯: {session_name}")
                except Exception as e:
                    logging.warning(f"å¯åŠ¨è½¬ç§»æ—¥å¿—ä¼šè¯å¤±è´¥: {e}")
            if not target_folders:
                raise FileOrganizerError("ç›®æ ‡ç›®å½•ä¸­æ²¡æœ‰æ–‡ä»¶å¤¹")
            if not files:
                raise FileOrganizerError("æ²¡æœ‰æ–‡ä»¶éœ€è¦æ•´ç†")
            results = {
                'total_files': len(files),
                'processed_files': 0,
                'successful_moves': 0,
                'failed_moves': 0,
                'skipped_files': 0,
                'success': [],
                'failed': [],
                'errors': [],
                'move_details': [],
                'ai_responses': [],
                'start_time': datetime.now(),
                'end_time': None,
                'transfer_log_file': log_session_name,
                'dry_run': dry_run
            }
            logging.info(f"å¼€å§‹å®‰å…¨æ–‡ä»¶æ•´ç†ï¼Œå…± {len(files)} ä¸ªæ–‡ä»¶")
            print(f"\n=== å¼€å§‹AIæ™ºèƒ½æ–‡ä»¶æ•´ç† ===")
            print(f"æºç›®å½•: {source_directory if source_directory else 'æŒ‡å®šæ–‡ä»¶åˆ—è¡¨'}")
            print(f"ç›®æ ‡ç›®å½•: {target_base_dir}")
            print(f"å¾…å¤„ç†æ–‡ä»¶æ€»æ•°: {len(files)}")
            print(f"æ“ä½œæ¨¡å¼: {'å¤åˆ¶' if copy_mode else 'ç§»åŠ¨'}")
            print("=" * 50)
            
            for i, file_info in enumerate(files, 1):
                file_path = str(file_info['path'])
                filename = str(file_info['name'])
                
                # è°ƒç”¨è¿›åº¦å›è°ƒ
                if progress_callback:
                    progress_callback(i, len(files), filename)
                
                # æ§åˆ¶å°è¾“å‡ºå½“å‰å¤„ç†è¿›åº¦
                print(f"\n[{i}/{len(files)}] æ­£åœ¨å¤„ç†: {filename}")
                
                try:
                    logging.info(f"æ­£åœ¨å¤„ç†æ–‡ä»¶ {i}/{len(files)}: {filename}")
                    print(f"  ğŸ” æ­£åœ¨åˆ†ææ–‡ä»¶å†…å®¹...", end="", flush=True)
                    target_folder, match_reason, success = self.classify_file(file_path, target_base_dir)
                    
                    results['ai_responses'].append({
                        'file_name': filename,
                        'target_folder': target_folder,
                        'match_reason': match_reason,
                        'success': success
                    })
                    
                    if not success or not target_folder:
                        error_msg = f"æ–‡ä»¶ {filename} åˆ†ç±»å¤±è´¥: {match_reason}ï¼Œå·²è·³è¿‡ï¼Œæœªåšä»»ä½•å¤„ç†"
                        print(f"\r  âŒ åˆ†ç±»å¤±è´¥: {match_reason}")
                        logging.warning(error_msg)
                        results['errors'].append(error_msg)
                        results['skipped_files'] += 1
                        results['failed'].append({
                            'source_path': file_path,
                            'error': error_msg
                        })
                        continue
                    
                    print(f"\r  âœ… æ¨èç›®å½•: {target_folder}")
                    print(f"     ç†ç”±: {match_reason}")
                    target_folder_path = Path(target_base_dir) / target_folder
                    if not target_folder_path.exists():
                        error_msg = f"ç›®æ ‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {target_folder}"
                        logging.error(error_msg)
                        results['errors'].append(error_msg)
                        results['failed_moves'] += 1
                        results['failed'].append({
                            'source_path': file_path,
                            'error': error_msg
                        })
                        continue
                    original_target_path = target_folder_path / filename
                    target_file_path = original_target_path
                    if target_file_path.exists():
                        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                        name_parts = filename.rsplit('.', 1)
                        if len(name_parts) == 2:
                            new_filename = f"{name_parts[0]}_{timestamp}.{name_parts[1]}"
                        else:
                            new_filename = f"{filename}_{timestamp}"
                        target_file_path = target_folder_path / new_filename
                        logging.info(f"æ–‡ä»¶åå†²çªï¼Œé‡å‘½åä¸º: {target_file_path.name}")
                    if not dry_run:
                        try:
                            if not Path(file_path).exists():
                                error_msg = f"æºæ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
                                logging.error(error_msg)
                                results['errors'].append(error_msg)
                                results['failed_moves'] += 1
                                results['failed'].append({
                                    'source_path': file_path,
                                    'error': error_msg
                                })
                                continue
                            if copy_mode:
                                shutil.copy2(file_path, str(target_file_path))
                                operation = "copy"
                                operation_cn = "å¤åˆ¶"
                            else:
                                shutil.move(file_path, str(target_file_path))
                                operation = "move"
                                operation_cn = "ç§»åŠ¨"
                            if target_file_path.exists():
                                if not copy_mode and Path(file_path).exists():
                                    error_msg = f"æ–‡ä»¶ç§»åŠ¨éªŒè¯å¤±è´¥: {filename}"
                                    logging.error(error_msg)
                                    results['errors'].append(error_msg)
                                    results['failed_moves'] += 1
                                    results['failed'].append({
                                        'source_path': file_path,
                                        'error': error_msg
                                    })
                                    continue
                                print(f"     âœ… {operation_cn}æˆåŠŸ: {filename} -> {target_folder}")
                                logging.info(f"æ–‡ä»¶å®‰å…¨{operation_cn}æˆåŠŸ: {filename} -> {target_folder} ({match_reason})")
                                results['successful_moves'] += 1
                            else:
                                error_msg = f"æ–‡ä»¶{operation_cn}éªŒè¯å¤±è´¥: {filename}"
                                logging.error(error_msg)
                                results['errors'].append(error_msg)
                                results['failed_moves'] += 1
                                results['failed'].append({
                                    'source_path': file_path,
                                    'error': error_msg
                                })
                                continue
                        except Exception as move_error:
                            error_msg = f"{operation_cn}æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {move_error}"
                            logging.error(error_msg)
                            results['errors'].append(error_msg)
                            results['failed_moves'] += 1
                            results['failed'].append({
                                'source_path': file_path,
                                'error': error_msg
                            })
                            continue
                    else:
                        operation = "copy" if copy_mode else "move"
                        operation_cn = "å¤åˆ¶" if copy_mode else "ç§»åŠ¨"
                        logging.info(f"[è¯•è¿è¡Œ] æ–‡ä»¶å°†{operation_cn}: {filename} -> {target_folder} ({match_reason})")
                        results['successful_moves'] += 1
                    if self.enable_transfer_log and self.transfer_log_manager and not dry_run:
                        try:
                            file_size_raw = file_info.get('size', 0)
                            file_size = int(file_size_raw) if isinstance(file_size_raw, (int, float, str)) and str(file_size_raw).isdigit() else 0
                            self.transfer_log_manager.log_transfer_operation(
                                source_path=file_path,
                                target_path=str(target_file_path),
                                operation_type=operation,
                                target_folder=target_folder,
                                success=True,
                                file_size=file_size
                            )
                        except Exception as e:
                            logging.warning(f"è®°å½•è½¬ç§»æ—¥å¿—å¤±è´¥: {e}")
                    results['success'].append({
                        'source_path': file_path,
                        'target_path': str(target_file_path),
                        'target_folder': target_folder,
                        'operation': operation
                    })
                    results['move_details'].append({
                        'source_file': file_path,
                        'file_name': filename,
                        'target_folder': target_folder,
                        'target_path': str(target_file_path),
                        'match_reason': match_reason,
                        'classification_method': 'AI',
                        'renamed': str(target_file_path) != str(original_target_path),
                        'operation': operation
                    })
                except Exception as e:
                    error_msg = f"å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºç°å¼‚å¸¸: {e}"
                    logging.error(error_msg)
                    results['errors'].append(error_msg)
                    results['failed_moves'] += 1
                    if self.enable_transfer_log and self.transfer_log_manager and not dry_run:
                        try:
                            operation_type = "copy" if copy_mode else "move"
                            self.transfer_log_manager.log_transfer_operation(
                                source_path=file_path,
                                target_path="",
                                operation_type=operation_type,
                                target_folder="",
                                success=False,
                                error_message=error_msg
                            )
                        except Exception as log_e:
                            logging.warning(f"è®°å½•å¤±è´¥è½¬ç§»æ—¥å¿—å¤±è´¥: {log_e}")
                    results['failed'].append({
                        'source_path': file_path,
                        'error': error_msg
                    })
                finally:
                    results['processed_files'] += 1
            results['end_time'] = datetime.now()
            
            # è¾“å‡ºå¤„ç†å®Œæˆæ€»ç»“
            print(f"\n=== æ–‡ä»¶æ•´ç†å®Œæˆ ===")
            print(f"æ€»æ–‡ä»¶æ•°: {results['total_files']}")
            print(f"æˆåŠŸå¤„ç†: {results['successful_moves']} ä¸ª")
            print(f"å¤„ç†å¤±è´¥: {results['failed_moves']} ä¸ª")
            print(f"è·³è¿‡æ–‡ä»¶: {results['skipped_files']} ä¸ª")
            duration = (results['end_time'] - results['start_time']).total_seconds()
            print(f"æ€»è€—æ—¶: {duration:.1f} ç§’")
            print("=" * 50)
            
            # ç”ŸæˆAIç»“æœJSONæ–‡ä»¶
            try:
                ai_results = []
                for ai_response in results['ai_responses']:
                    # è·å–å¯¹åº”çš„è¯¦ç»†åˆ†æç»“æœ
                    file_name = ai_response['file_name']
                    file_path = next((f['path'] for f in files if Path(f['path']).name == file_name), None)
                    
                    if file_path:
                        # é‡æ–°åˆ†ææ–‡ä»¶ä»¥è·å–å®Œæ•´ä¿¡æ¯
                        analysis_result = self.analyze_and_classify_file(str(file_path), target_base_dir)
                        
                        ai_result = {
                            'file_name': file_name,
                            'file_path': str(file_path),
                            'extracted_content': analysis_result.get('extracted_content', '')[:200] + "..." if len(analysis_result.get('extracted_content', '')) > 200 else analysis_result.get('extracted_content', ''),
                            'content_summary': analysis_result.get('content_summary', ''),
                            'recommended_folder': analysis_result.get('recommended_folder', ''),
                            'match_reason': analysis_result.get('match_reason', ''),
                            'success': analysis_result.get('success', False),
                            'timing_info': analysis_result.get('timing_info', {})
                        }
                        ai_results.append(ai_result)
                
                # ä¿å­˜AIç»“æœåˆ°JSONæ–‡ä»¶
                ai_result_file = 'ai_organize_result.json'
                with open(ai_result_file, 'w', encoding='utf-8') as f:
                    json.dump(ai_results, f, ensure_ascii=False, indent=2)
                logging.info(f"AIåˆ†æç»“æœå·²ä¿å­˜åˆ°: {ai_result_file}")
                results['ai_result_file'] = ai_result_file
                
            except Exception as e:
                logging.warning(f"ç”ŸæˆAIç»“æœæ–‡ä»¶å¤±è´¥: {e}")
            
            if self.enable_transfer_log and self.transfer_log_manager and not dry_run:
                try:
                    session_summary = self.transfer_log_manager.end_transfer_session()
                    logging.info(f"è½¬ç§»æ—¥å¿—ä¼šè¯ç»“æŸ: {session_summary}")
                except Exception as e:
                    logging.warning(f"ç»“æŸè½¬ç§»æ—¥å¿—ä¼šè¯å¤±è´¥: {e}")
            
            logging.info(f"å®‰å…¨æ–‡ä»¶æ•´ç†å®Œæˆ: æˆåŠŸ {results['successful_moves']}, å¤±è´¥ {results['failed_moves']}, è·³è¿‡ {results['skipped_files']}")
            return results
        except Exception as e:
            raise FileOrganizerError(f"æ‰¹é‡æ•´ç†æ–‡ä»¶å¤±è´¥: {e}")
    def get_transfer_logs(self) -> List[str]:
        if not self.enable_transfer_log or not self.transfer_log_manager:
            raise FileOrganizerError("è½¬ç§»æ—¥å¿—åŠŸèƒ½æœªå¯ç”¨")
        return self.transfer_log_manager.get_transfer_logs()
    def get_transfer_log_summary(self, log_file_path: str) -> Dict:
        if not self.enable_transfer_log or not self.transfer_log_manager:
            raise FileOrganizerError("è½¬ç§»æ—¥å¿—åŠŸèƒ½æœªå¯ç”¨")
        return self.transfer_log_manager.get_session_summary(log_file_path)
    def restore_files_from_log(self, log_file_path: str, operation_ids: Optional[List[int]] = None, dry_run: bool = True) -> Dict:
        if not self.enable_transfer_log or not self.transfer_log_manager:
            raise FileOrganizerError("è½¬ç§»æ—¥å¿—åŠŸèƒ½æœªå¯ç”¨")
        try:
            restore_results = self.transfer_log_manager.restore_from_log(
                log_file_path=log_file_path,
                operation_ids=operation_ids if operation_ids is not None else [],
                dry_run=dry_run
            )
            logging.info(f"æ–‡ä»¶æ¢å¤å®Œæˆ: æˆåŠŸ {restore_results['successful_restores']}, å¤±è´¥ {restore_results['failed_restores']}, è·³è¿‡ {restore_results['skipped_operations']}")
            return restore_results
        except Exception as e:
            raise FileOrganizerError(f"æ–‡ä»¶æ¢å¤å¤±è´¥: {e}")
    def cleanup_old_transfer_logs(self, days_to_keep: int = 30) -> int:
        if not self.enable_transfer_log or not self.transfer_log_manager:
            raise FileOrganizerError("è½¬ç§»æ—¥å¿—åŠŸèƒ½æœªå¯ç”¨")
        return self.transfer_log_manager.cleanup_old_logs(days_to_keep)
    def get_file_summary(self, file_path: str, max_length: int = 50, max_pages: int = 2, max_seconds: int = 10) -> str:
        """
        è‡ªåŠ¨é€‚é… txt/pdf/docx æ ¼å¼ï¼Œè¿”å›å‰max_lengthå­—æ‘˜è¦ï¼ŒPDF/Wordåªå–å‰max_pagesé¡µï¼Œå•æ–‡ä»¶å¤„ç†è¶…æ—¶max_secondsç§’ã€‚
        """
        ext = Path(file_path).suffix.lower()
        start_time = time.time()
        try:
            if ext == '.txt':
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    return f.read(max_length)
            elif ext == '.pdf':
                with open(file_path, 'rb') as f:
                    reader = PyPDF2.PdfReader(f)
                    text = ''
                    for i, page in enumerate(reader.pages):
                        if i >= max_pages or (time.time() - start_time) > max_seconds:
                            break
                        page_text = page.extract_text() or ''
                        text += page_text
                        if len(text) >= max_length:
                            break
                    if (time.time() - start_time) > max_seconds:
                        return 'æå–è¶…æ—¶ï¼Œå·²è·³è¿‡'
                    return text[:max_length] if text else 'æœªèƒ½æå–æ­£æ–‡'
            elif ext == '.docx':
                doc = docx.Document(file_path)
                text = ''
                for i, para in enumerate(doc.paragraphs):
                    if (time.time() - start_time) > max_seconds:
                        break
                    text += para.text
                    if len(text) >= max_length:
                        break
                if (time.time() - start_time) > max_seconds:
                    return 'æå–è¶…æ—¶ï¼Œå·²è·³è¿‡'
                return text[:max_length] if text else 'æœªèƒ½æå–æ­£æ–‡'
            else:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    return f.read(max_length)
        except Exception as e:
            if (time.time() - start_time) > max_seconds:
                return 'æå–è¶…æ—¶ï¼Œå·²è·³è¿‡'
            return f'æ‘˜è¦è·å–å¤±è´¥: {e}'